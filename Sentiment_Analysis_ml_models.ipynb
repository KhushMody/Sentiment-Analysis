{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Samsung_prism.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-4iXoNw8Umo"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import spacy\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "from nltk.tokenize import RegexpTokenizer, WhitespaceTokenizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "from string import punctuation\n",
        "import collections\n",
        "from collections import Counter\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "#import en_core_web_smfrom sklearn.feature_extraction.text import CountVectorizer, TfidfTransformerfrom sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import jaccard_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZFp4Wv-AEOJ"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import re\n",
        "\n",
        "# Data Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import plotly.figure_factory as ff\n",
        "from plotly.colors import n_colors\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "import missingno as msno\n",
        "\n",
        "\n",
        "import seaborn as sns\n",
        "sns.set(style='whitegrid')\n",
        "\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJ1vT2e78dbV"
      },
      "source": [
        "tweets_data_path = '/content/Corona_NLP_train.csv'\n",
        "train = pd.read_csv(tweets_data_path, encoding = 'latin-1')\n",
        "test = pd.read_csv('/content/Corona_NLP_test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLYdI5KQAyv_"
      },
      "source": [
        "len(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUsgE6Y896xE"
      },
      "source": [
        "train.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uv_9Ui9vAeIv"
      },
      "source": [
        "train['UserName'].nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bs9ZsLj0At_9"
      },
      "source": [
        "train['ScreenName'].nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MYLqWouAxj1"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5OdfjHTA5L5"
      },
      "source": [
        "def remove_urls(text):\n",
        "    return re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', text)\n",
        "train['Content']=train['OriginalTweet'].apply(lambda x:remove_urls(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OT6aX7RZBc3h"
      },
      "source": [
        "def remove_urls(text):\n",
        "    return re.sub(r'<.*?>', '', text)\n",
        "train['Content']=train['Content'].apply(lambda x:remove_urls(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MHcgyenBf5g"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mp3Sm1ipC7wy"
      },
      "source": [
        "def remove_pattern(input_txt, pattern):\n",
        "    r = re.findall(pattern, input_txt)\n",
        "    for i in r:\n",
        "        input_txt = re.sub(i,'',input_txt)\n",
        "    return input_txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0QfSdMhDrW6"
      },
      "source": [
        "train['pfinal'] = np.vectorize(remove_pattern)(train['Content'], '@[\\w]*')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zunmsHOAD40f"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGTiKVQ8D6gs"
      },
      "source": [
        "import re\n",
        "train['final'] = train['pfinal'].apply(lambda x: re.split('https:\\/\\/.*', str(x))[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XONvOjCGEe0L"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YajsrY3bEgjp"
      },
      "source": [
        "train['final'] = train['final'].str.replace('[^a-zA-Z#]+',' ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2Awyyg3Ep0H"
      },
      "source": [
        "train['final'] = train['final'].apply(lambda x: ' '.join([w for w in x.split() if len(w) > 2]))\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtcUTTAiE0zC"
      },
      "source": [
        "tokenized_tweet = train['final'].apply(lambda x: x.split())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZl0qgQfE-Fj"
      },
      "source": [
        "from nltk.stem.porter import *\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "# apply stemmer for tokenized_tweet\n",
        "tokenized_tweet = tokenized_tweet.apply(lambda x: [stemmer.stem(i) for i in x])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4lBTbbKFDmJ"
      },
      "source": [
        "train.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSXj9e1cFJ26"
      },
      "source": [
        "for i in range(len(tokenized_tweet)):\n",
        "    tokenized_tweet[i] = ' '.join(tokenized_tweet[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2v_PcS_FVz5"
      },
      "source": [
        "train['final'] = tokenized_tweet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wKe8JU0FZPw"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6EQp763Fap7"
      },
      "source": [
        "new_df = train[['final','Sentiment']]\n",
        "new_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVDH6wFCGObQ"
      },
      "source": [
        "train['Sentiment'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9B_WKw6GXaU"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4EGg1JQG7Ei"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6S5mMzRG9Wm"
      },
      "source": [
        "new_df['final'].apply(lambda x: [item for item in x if item not in stop])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rO6dWobEG_4A"
      },
      "source": [
        "new_df.head(6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31Dy7_M3HRaX"
      },
      "source": [
        "new_df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2_Kp6GyHbJV"
      },
      "source": [
        "new_df.final[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18uDpRXgHjw7"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train,valid = train_test_split(new_df,test_size = 0.2,random_state=0,stratify = new_df.Sentiment.values) \n",
        "print(\"train shape : \", train.shape)\n",
        "print(\"valid shape : \", valid.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPZxUz4cH8FF"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "stop = list(stopwords.words('english'))\n",
        "vectorizer = CountVectorizer(decode_error = 'replace',stop_words = stop)\n",
        "\n",
        "X_train = vectorizer.fit_transform(train.final.values)\n",
        "X_valid = vectorizer.transform(valid.final.values)\n",
        "\n",
        "y_train = train.Sentiment.values\n",
        "y_valid = valid.Sentiment.values\n",
        "\n",
        "print(\"X_train.shape : \", X_train.shape)\n",
        "print(\"X_train.shape : \", X_valid.shape)\n",
        "print(\"y_train.shape : \", y_train.shape)\n",
        "print(\"y_valid.shape : \", y_valid.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOaCqM9pInBD"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "naiveByes_clf = MultinomialNB()\n",
        "\n",
        "naiveByes_clf.fit(X_train,y_train)\n",
        "\n",
        "NB_prediction = naiveByes_clf.predict(X_valid)\n",
        "NB_accuracy = accuracy_score(y_valid,NB_prediction)\n",
        "print(\"training accuracy Score    : \",naiveByes_clf.score(X_train,y_train))\n",
        "print(\"Validation accuracy Score : \",NB_accuracy )\n",
        "print(classification_report(NB_prediction,y_valid))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64GAWtgLI1Hu"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf_clf = RandomForestClassifier()\n",
        "\n",
        "rf_clf.fit(X_train,y_train)\n",
        "\n",
        "rf_prediction = rf_clf.predict(X_valid)\n",
        "rf_accuracy = accuracy_score(y_valid,rf_prediction)\n",
        "print(\"Training accuracy Score    : \",rf_clf.score(X_train,y_train))\n",
        "print(\"Validation accuracy Score : \",rf_accuracy )\n",
        "print(classification_report(rf_prediction,y_valid))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfTmp5yiJhfS"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svc = SVC()\n",
        "\n",
        "svc.fit(X_train, y_train)\n",
        "\n",
        "svc_prediction = svc.predict(X_valid)\n",
        "svc_accuracy = accuracy_score(y_valid,svc_prediction)\n",
        "print(\"Training accuracy Score    : \",svc.score(X_train,y_train))\n",
        "print(\"Validation accuracy Score : \",svc_accuracy )\n",
        "print(classification_report(svc_prediction,y_valid))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2gyIykZJmba"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}